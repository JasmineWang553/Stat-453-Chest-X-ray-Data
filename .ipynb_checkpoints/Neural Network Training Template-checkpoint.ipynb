{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    Subset\n",
    ") \n",
    "\n",
    "# other\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from skimage import io\n",
    "import time\n",
    "import copy\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# helper functions\n",
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix, compute_accuracy\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from helper_dataset import UnNormalize\n",
    "from data_loading_functions import split_train_test_loaders, show_img, convert_lab\n",
    "from helper_gradcam import store_gradcam_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '.\\\\COVID-19_Radiography_Dataset'\n",
    "datas, train_loader, valid_loader, test_loader = split_train_test_loaders(dataset_path, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_img(dataset_path= dataset_path, train= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_img(dataset_path= dataset_path, train= True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 224*224\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Other\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained models\n",
    "model_ft = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# fine tune fully connected layer\n",
    "for name, child in model_ft.named_children():\n",
    "    if name in ['classifier']:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# fine tune last feature layer\n",
    "for param in model_ft.features[-1:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# change out_features of last linear layer\n",
    "model_ft.classifier[6] = nn.Linear(in_features=4096, out_features=4, bias=True)\n",
    "\n",
    "\n",
    "# Train\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model_ft.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)  \n",
    "\n",
    "minibatch_loss_list_ft, train_acc_list_ft, valid_acc_list_ft = train_model(num_epochs = NUM_EPOCHS, model = model_ft, \n",
    "                                                                optimizer = optimizer, device = DEVICE, \n",
    "                                                                train_loader = train_loader, valid_loader=valid_loader, \n",
    "                                                                test_loader = test_loader, logging_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(minibatch_loss_list_ft, label='Minibatch cost')\n",
    "plt.plot(np.convolve(minibatch_loss_list_ft, \n",
    "                     np.ones(200,)/200, mode='valid'), \n",
    "         label='Running average')\n",
    "\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, NUM_EPOCHS+1), train_acc_list_ft, label='Training')\n",
    "plt.plot(np.arange(1, NUM_EPOCHS+1), valid_acc_list_ft, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.cpu()\n",
    "unnormalizer = UnNormalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.2255))\n",
    "class_dict  = {0: 'COVID', 1: 'Lung_Opacity', 2: 'Normal', 3: 'Viral Pneumonia'}\n",
    "\n",
    "show_examples(model=model_ft, data_loader=test_loader, unnormalizer=unnormalizer, class_dict=class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = compute_confusion_matrix(model=model_ft, data_loader=test_loader, device=torch.device('cpu'))\n",
    "plot_confusion_matrix(mat, class_names=class_dict.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.to(DEVICE)\n",
    "\n",
    "for param in model_ft.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "store_gradcam_image(model_ft, model.features, ['12'], 'Alexnet', 'COVID', 744) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
